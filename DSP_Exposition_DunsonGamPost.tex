\documentclass[11pt]{article}


\usepackage[margin=2cm]{geometry}
\usepackage[fleqn]{amsmath}
\usepackage{mathtools}  %% Use for spreadlines, MoveEqLeft
\usepackage{bigints}  %% Use for larger integral sign
\usepackage{enumitem}
\usepackage{color}
\usepackage{titlesec}


  %% User-defined commands %%
\newcommand{\prob}{\mathbb{P}\,}
\newcommand{\ev}{\mathbb{E}\,}
\newcommand{\var}{\text{Var}\,}
\renewcommand{\vec}{\boldsymbol}
\newcommand{\barS}{\,|\,}
\newcommand{\barM}{~\big|~}
\newcommand{\barB}{~\Big|~}
\newcommand{\barBBB}{~\Bigg|~}
\newcommand{\ind}{I}
%\newcommand{\cdotB}{ \scalebox{1}{$\ldot$} }
\newcommand{\cdotB}{\raisebox{-0.5ex}{\scalebox{1.75}{$\cdot$}}}
\newcommand{\gammaExpr}{ -\hspace{3mm} \sum_{\mathclap{i,j,k{:}\, X_{ijk}=1}} \hspace{4mm} \xi_i \prod_{\ell=1}^q \gamma_\ell^{ u_{ijk\ell} } }
\newcommand{\gammaExprNoH}{ -\hspace{3mm} \sum_{\mathclap{i,j,k{:}\, X_{ijk}=1}} \hspace{4mm} \xi_i \prod_{\ell \ne h} \gamma_\ell^{ u_{ijk\ell} } }
\newcommand{\gammaExprUisZero}{ \hspace{3mm} \sum_{\mathclap{\substack{i,j,k{:}\, X_{ijk}=1, \\ u_{ijkh} = 0}}} \hspace{4mm} \xi_i \prod_{\ell \ne h} \gamma_\ell^{ u_{ijk\ell} } }
\newcommand{\gammaExprUisOne}{ \hspace{3mm} \sum_{\mathclap{\substack{i,j,k{:}\, X_{ijk}=1, \\ u_{ijkh} = 1}}} \hspace{4mm} \xi_i \prod_{\ell \ne h} \gamma_\ell^{ u_{ijk\ell} } }

  %% Font choice Bakervald X %%
% \usepackage{txfonts}
% \usepackage[T1]{fontenc}
% \usepackage[mathscr]{euscript}
% \renewcommand{\ttdefault}{cmtt}    %% Restore default typewriter font

  %% Font choice %%
\usepackage[bitstream-charter]{mathdesign}
\usepackage[T1]{fontenc}
\SetMathAlphabet{\mathcal}{normal}{OMS}{cmsy}{m}{n}  %% Restore default mathcal font


\allowdisplaybreaks[2]  %% Allow page breaks in align, 1-4 is least permissible to most

\definecolor{QuestCol}{RGB}{150,0,0}  %% Define color to highlight questionable parts in

\titlespacing*{\section}{0pt}{20mm plus 1ex minus .2ex}{2ex plus .2ex}
\titlespacing*{\subsection}{0pt}{10mm plus 1ex minus .2ex}{2ex plus .2ex}
\titlespacing*{\subsubsection}{0pt}{10mm plus 1ex minus .2ex}{2ex plus .2ex}






\begin{document}


% ==============================================================================

\setcounter{section}{-1}
\section{Introduction}
The goal of this document is to fully characterize the Dunson and Stanford day-specific probabilities model.  In its current state it tries to provide full detail of the derivations described in \textit{Bayesian Inferences on Predictors of Conception Probabilities}.


% ==============================================================================

\section{The day-specific probabilities model}





% ------------------------------------------------------------------------------

\subsection{Model specification}
We wish to model the probability of a woman becoming pregnant for a given menstrual cycle as a function of her covariate status across the days of the cycle.  Consider a study cohort and let us index
\[ \begin{array}{lll}
\text{woman } i, & & i = 1,\dots,n   \\[1ex]
\text{cycle } j, & & j = 1,\dots,n_i \\[1ex]
\text{day }   k, & & k = 1,\dots,K
\end{array} \]
where day $k$ refers to the $k^\text{th}$ day out of a total of $K$ days in the fertile window.  Let us write day $i,j,k$ as a shorthand for individual $i$, cycle $j$, and day $k$ and similarly for cycle $j,k$.  Then define
\[ \begin{array}{lll}
Y_{ij} & & \text{an indicator of conception for woman $i$, cycle $j$} \\[1ex]
V_{ijk} & & \text{an indicator of conception for woman $i$, cycle $j$, day $k$} \\[1ex]
X_{ijk} & & \text{an indicator of intercourse for woman $i$, cycle $j$, day $k$} \\[1ex]
\end{array}  \]
Then writing $\vec{X}_{ij} = \big( X_{ij1}, \dots, X_{ijK} \big)$, we observe that
\begin{align*} \MoveEqLeft
\prob\Big( Y_{ij} = 1 \barM \vec{X}_{ij},~ Y_{i1} = 0,\dots, Y_{i,j-1} = 0  \Big) \\[1ex]
&= 1 - \prob\Big( Y_{ij} = 0 \barM \vec{X}_{ij},~ Y_{i1} = 0,\dots, Y_{i,j-1} = 0 \Big) \\[1ex]
&= 1 - \prob\Big( V_{ijk} = 0,~ k=1,\dots,K \barM \vec{X}_{ij},~ Y_{i1} = 0,\dots, Y_{i,j-1} = 0 \Big) \\
&= 1 - \prod_{k=1}^K\, \prob\Big( V_{ijk} = 0 \barM X_{ijk},~ Y_{i1} = 0,\dots, Y_{i,j-1} = 0,~ V_{ij1} = 0, \dots, V_{i,k-1} = 0 \Big) \\
% &= 1 - \prod_{k=1}^K\, X_{ijk}\, \prob\Big( V_{ijk} = 0 \barM Y_{i1} = 0,\dots, Y_{i,k-1} = 0,~ V_{ij1} = 0, \dots, V_{ij,k-1} = 0 \Big) \\
&= 1 - \prod_{k=1}^K\, \Bigg\{ 1 - \prob\Big( V_{ijk} = 1 \barM X_{ijk},~ Y_{i1} = 0,\dots, Y_{i,j-1} = 0,~ V_{ij1} = 0, \dots, V_{i,k-1} = 0 \Big) \Bigg\} \\
&= 1 - \prod_{k=1}^K\, \Bigg\{ 1 - X_{ijk}\, \prob\Big( V_{ijk} = 1 \barM Y_{i1} = 0,\dots, Y_{i,j-1} = 0,~ V_{ij1} = 0, \dots, V_{i,k-1} = 0 \Big) \Bigg\} \\
&= 1 - \prod_{k=1}^K\, \Bigg\{ 1 - \prob\Big( V_{ijk} = 1 \barM Y_{i1} = 0,\dots, Y_{i,j-1} = 0,~ V_{ij1} = 0, \dots, V_{i,k-1} = 0 \Big) \Bigg\}^{X_{ijk}} \\
\end{align*}
With this result in mind, we now consider the Dunson and Stanford day-specific probabilities model.  Using the same indexing scheme as above, define
\[ \begin{array}{lll}
\vec{u}_{ijk} & & \text{a covariate vector of length $q$ for  woman $i$, cycle $j$, day $k$} \\[1ex]
\vec{\beta} & & \text{a vector of length $q$ of regression coefficients} \\[1ex]
\xi_i & & \text{woman-specific random effect} \\
\end{array} \]
Then writing $\vec{U}_{ij} = \big( \vec{u}_{ijk}^\prime, \dots, \vec{u}_{ijk}^\prime \big)^\prime$, Dunson and Stanford propose the model:
\begin{align} \label{eq: DSP model}
\prob\Big( Y_{ij} = 1 ~\big|~ \xi_i, \vec{X}_{ij}, \vec{U}_{ij} \Big) &= 1 - \prod_{k=1}^K\, (1 - \lambda_{ijk})^{X_{ijk}} \nonumber \\
\lambda_{ijk} &= 1 - \exp\left\{ -\xi_i \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) \right\} \nonumber \\[1ex]
\xi_i &\sim \text{Gamma}\,(\phi,\phi)
\end{align}

\noindent From our previous derivation, we see that we may interpret $\lambda_{ijk}$ as the day-specific probability of conception in cycle $j$ from couple $i$ given that conception has not already occured, or in the language of Dunson and Stanford, given intercourse only on day $k$.

Delving further, we see that $\lambda_{ijk}$ is strictly increasing in $u_{ijkh}\, \beta_{h}$, where we are denoting $u_{ijkh}$ to be the $h^{\text{th}}$ term in $\vec{u}_{ijk}$ and similarly for $\beta_h$.  When $\beta_h = 0$ then the $h^{\text{th}}$ covariate has no effect on the day-specific probability of conception.

$\lambda_{ijk}$ is also strictly increasing in $\xi_i$ which as Dunson and Stanford suggest may be interpreted as a woman-specific random effect.  The authors state that specifying the distribution of the $\xi_i$ with a common parameters prevents nonidentifiability between $\ev [\xi_i]$ and the day-specific parameters.  Since $\var[\xi_i] = 1 / \phi$ it follows that $\phi$ may be interpreted as a measure of variability across women. 




% ------------------------------------------------------------------------------

\subsubsection{Computation consideration}

As an aside, we note that it may be more computationally convenient to calculate
\begin{align*} \MoveEqLeft
\prob\Big( Y_{ij} = 1 ~\big|~ \xi_i, \vec{X}_{ij}, \vec{U}_{ij}  \Big) \\[1ex]
&= 1 - \prod_{k=1}^K\, (1 - \lambda_{ijk})^{X_{ijk}} \\
&= 1 - \prod_{k=1}^K\, \bigg[ \exp \left\{ -\xi_i \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) \right\} \bigg]^{\,X_{ijk}} \\
&= 1 - \prod_{k=1}^K\, \exp \left\{ -X_{ijk} \xi_i \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) \right\} \\
&= 1 - \exp \left\{ - \sum_{k=1}^K X_{ijk} \xi_i \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) \right\}
\end{align*}






% ------------------------------------------------------------------------------

\subsection{Marginal probability of conception}

The marginal probability of conception, obtained by integrating out the couple-specific frailty $\xi_i$, has form as follows.
\begin{align*} \MoveEqLeft
\prob (Y_{ij} = 1 \barS \vec{X}_{ij}, \vec{U}_{ij}) \\[1ex]
&= \int_0^\infty \prob \Big( Y_{ij}, \xi_i \barS \vec{X}_{ij}, \vec{U}_{ij} \Big)\, d\xi_i \\[1ex]
&= \int_0^\infty \prob \Big( Y_{ij}, \xi_i \barS \vec{X}_{ij}, \vec{U}_{ij} \Big)\, \mathcal{G}(\xi_i;\, \phi,\phi)\, d\xi_i \\[1ex]
&= \int_0^\infty \left[ 1 - \prod_{k=1}^K (1 - \lambda_{ijk})^{X_{ijk}} \right] \mathcal{G}(\xi_i;\, \phi,\phi)\, d\xi_i \\[1ex]
&= 1 - \int_0^\infty \prod_{k=1}^K (1 - \lambda_{ijk})^{X_{ijk}}\, \mathcal{G}(\xi_i;\, \phi,\phi)\, d\xi_i \\[1ex]
&= 1 - \int_0^\infty \prod_{k=1}^K\, \bigg[ \exp\left\{ -\xi_i \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right)\right\} \bigg]^{\,X_{ijk}} \mathcal{G}(\xi_i;\, \phi,\phi)\, d\xi_i \\[1ex]
&= 1 - \int_0^\infty \prod_{k=1}^K\, \exp\bigg\{ -\xi_i X_{ijk} \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right)\bigg\}\, \mathcal{G}(\xi_i;\, \phi,\phi)\, d\xi_i \\[1ex]
&= 1 - \int_0^\infty \exp\left\{ -\xi_i \sum_{k=1}^K X_{ijk} \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right)\right\} \mathcal{G}(\xi_i;\, \phi,\phi)\, d\xi_i \\
&= 1 - \left[ \frac{ \phi }{ \phi + \sum_{k=1}^K X_{ijk} \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) } \right]^\phi
\end{align*}
since
\begin{align*} \MoveEqLeft
\bigintssss_{\,0}^{\!\infty} \exp\left\{ -\xi_i \sum_{k=1}^K X_{ijk} \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right)\right\} \mathcal{G}(\xi_i;\, \phi,\phi)\, d\xi_i \\[1ex]
&= \bigintssss_{\,0}^{\!\infty} \exp\left\{ -\xi_i \sum_{k=1}^K X_{ijk} \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right)\right\} \frac{ \phi^\phi }{ \Gamma(\phi) }\, \xi_i^{\phi-1} d\xi_i \\[1ex]
&= \bigintssss_{\,0}^{\!\infty} \frac{ \phi^\phi }{ \Gamma(\phi) }\, \xi_i^{\phi-1} \exp\left\{ -\xi_i \left[ \phi + \sum_{k=1}^K X_{ijk} \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) \right]\, \right\} d\xi_i \\[1ex]
&= \left[ \frac{ \phi }{ \phi + \sum_{k=1}^K X_{ijk} \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) } \right]^\phi \bigintsss_{\,0}^{\!\infty} \frac{ \left[ \phi + \sum_{k=1}^K X_{ijk} \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) \right]^\phi }{ \Gamma(\phi) } \\
& \hspace{50mm} \times \xi_i^{\phi-1} \exp \left\{ -\xi_i \left[ \phi + \sum_{k=1}^K X_{ijk} \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) \right]^\phi \right\} d\xi_i
\end{align*}
and the function inside the integral is a gamma density function.




%-------------------------------------------------------------------------------

\subsubsection{Day-specific marginal probability of conception}
Dunson and Stanford also point out the following remarkable result.  The marginal day-specific probability of conception in a cycle with intercourse only on day $k$ and with predictors $\vec{u}$ is given by
\[ \prob( Y = 1 \barS \vec{u} ) = 1 - \left( \frac{ \phi }{ \phi + \exp(\vec{u}^\prime \vec{\beta}) } \right)^\phi \]
which is in the form of the Aranda-Ordaz generalized linear model, and reduces to a logistic regression model for $\phi = 1$.






%-------------------------------------------------------------------------------

\subsection{Prior specification}

Define 
\[ \begin{array}{lll}
\mathcal{G}_{\!\mathcal{A}_h} ( \cdotB ) & & \text{density function of a gamma distribution truncated to the region $\mathcal{A}_h \subset (0,\infty)$} \\[1ex]
\gamma_h & & \exp( \beta_h ) 
\end{array} \]
Then the Dunson and Stanford model chooses priors of the form
\[ \begin{array}{l}
\pi\,(\vec{\gamma}) = \displaystyle \prod_{h=1}^q \bigg\{ p_h \ind\big( \gamma_h = 1 \big) ~+~ (1 - p_h)\, \ind\big( \gamma_h \ne 1 \big)\, \mathcal{G}_{\mathcal{A}_h} \big( \gamma_h;~ a_h, b_h \big) \bigg\} \\[3ex]
\pi(\phi) = \mathcal{G}\, \big(\phi;~ c_1, c_2\big) \\
\end{array} \]
where
\[ \begin{array}{lll}
p_h & & \text{prior probability that $\gamma_h=1$, a hyperparameter} \\[1ex]
a_h,b_h & & \text{shape and rate hyperparameters for gamma distribution of $\gamma_h$} \\[1ex]
c_1,c_2 & & \text{shape and rate hyperparameters for gamma distribution of $\phi$} \\
\end{array} \] \vspace{2mm}

\noindent Values of $\gamma_h = 1$ correspond to $\beta_h = 0$ and the $h^{\text{th}}$ predictor in $\vec{u}_{ijk}$ being dropped from the model.  Thus assigning the prior for each of the $\gamma_h$ to be a mixture distribution between a point mass at one and a gamma distribution allows the model to drop terms from the regression component with nonzero probability.

Typical constraints for the $\gamma_h$ are $\mathbb{R}^+,\, (0,1)$, and $(1,\infty)$ which correspond to no constraint, a negative effect on probability of conception, and a positive effect on probability of conception, respectively.  Thus a priori knowledge of the direction of association of the predictor variables can be incorporated into the model to decrease posterior uncertainty.

\subsubsection{Monotone effects}

Consider a model where the list of covariates includes an ordered categorical variable with types $1,\dots,t$.  Let $\vec{s}_{ijk} = \big( s_{ijk,2}, \dots, s_{ijk,t} \big)$ be a vector of length $(t-1)$ for each day $i,j,k$ where
\[ \arraycolsep=2pt \begin{array}{ccl}
s_{ijk,2} & = & I\,\Big(\, \text{categorical variable for day $i,j,k$ is type 2} \,\Big) \\[1ex]
s_{ijk,3} & = & I\,\Big(\, \text{categorical variable for day $i,j,k$ is type 2 or 3} \,\Big) \\[1ex]
\vdots & \vdots & \hspace{45mm} \vdots \\
s_{ijk,t} & = & I\,\Big(\, \text{categorical variable for day $i,j,k$ is type 2 or 3 or \dots or $t$} \,\Big)
\end{array} \]
Next, let us partition each covariate vector $\vec{u}_{ijk} = \big(\vec{r}_{ijk},\,  \vec{s}_{ijk}\big)$ so that $\vec{r}_{ijk}$ is a vector of the remaining covariate terms.  Furthermore let $\vec{\beta} = \big( \vec{\tau},\, \vec{\alpha} \big)$ be the corresponding partition of covariate coefficients where $\vec{\alpha} = \big(\alpha_2,\dots,\alpha_t\big)$.  Then for person $i$, cycle $j$, and day $k$ with categorical variable type $d$ where $d \in \{1,\dots,t\}$, then
\begin{align*}
\lambda_{ijk} &= 1 - \exp\left\{ -\xi_i \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) \right\} \\[1ex]
&= 1 - \exp\left\{ -\xi_i \exp\left( \vec{r}_{ijk}^\prime \vec{\tau} + \vec{s}_{ijk}^\prime \vec{\alpha} \right) \right\} \\
&= 1 - \ind\,\big( d = 1 \big)\, \exp\left\{ -\xi_i \exp\left( \vec{r}_{ijk}^\prime \vec{\tau} \right) \right\} - \ind\,\big( d \geq 2 \big)\, \exp\left\{ -\xi_i \exp\left( \vec{r}_{ijk}^\prime \vec{\tau} + \sum_{m=2}^d \alpha_m \right) \right\}
\end{align*}
From this form we can see that when $\alpha_m \geq 0,~ m=2,\dots,t$ then $\lambda_{ijk}$ is nondecreasing in $m$.  It follows that a monotone increasing categorical variable can be created by coding the variable in the format as described above, and constraining the corresponding parameters of $\gamma_h$ to be greater than or equal to one (corresonding to $\beta_h \geq 0$ for each of the corresonding $h$).  Similarly, a monotone decreasing categorical variable can be created by coding the variable as described above, and constraining the corresponding parameters of $\gamma_h$ to be less than or equal to one.









%-------------------------------------------------------------------------------

\section{Posterior computation}

Express the data augmentation model as
\begin{align} \label{eq: Data augmentation model}
& Y_{ij} = \ind \left( \sum_{k=1}^K X_{ijk} Z_{ijk} > 0 \right), \nonumber \\[1ex]
% & W_{ijk} \stackrel{\mathit{ind}}{\sim} \left\{ \begin{array}{lll} 0, & & X_{ijk} = 0 \\[1ex]  \text{Poisson}\left( \xi_i \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right)\right), & & \text{else} \end{array} \right.
& Z_{ijk} \sim \text{Poisson}\left( \xi_i \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right)\right), \hspace{5mm}  k=1,\dots,K
\end{align} \\
Let us further define $W_{ijk} = X_{ijk} Z_{ijk}$ for all $i,j,k$.




%-------------------------------------------------------------------------------

\subsection{Verifying the equivalence of the data augmentation model}

Under (\ref{eq: Data augmentation model}), $Y_{ij} = 0$ if and only if $W_{ij1}, \dots, W_{ijK}$ are identically 0.  It follows that
\begin{align*} \MoveEqLeft
\prob \Big( Y_{ij} = 0 \barM \xi_i, \vec{X}_{ij}, \vec{U}_{ij} \Big) \\
&= \prod_{k{:}\, X_{ijk} = 1} \prob\Big( W_{ijk} = 0 \barM \xi_i, \vec{u}_{ijk} \Big) \\
&= \hspace{2.75mm} \prod_{k = 1}^K~ \bigg[ \prob\Big( W_{ijk} = 0 \barM \xi_i, \vec{u}_{ijk} \Big) \bigg]^{X_{ijk}} \\
&= \hspace{2.75mm} \prod_{k = 1}^K~ \bigg[ \exp\left\{ \xi_i \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right)\right\} \bigg]^{X_{ijk}} \\
&= \hspace{2.75mm} \prod_{k = 1}^K~ (1 - \lambda_{ijk})^{X_{ijk}}
\end{align*}
which is the model in (\ref{eq: DSP model}).




%-------------------------------------------------------------------------------

\subsection{The full likelihood}

Let $\vec{Y}$ be a random variable representing all of the potential pregnancy indicators $Y_{ij}$, let $\vec{W}$ be a random variable representing all of the latent variables $W_{ijk}$, and let $\xi$ be a random variable representing all of the woman-specific random effects $\xi_i$.  Then
\begin{align*} \MoveEqLeft
\pi\,\big( \vec{Y}, \vec{W}, \vec{\gamma}, \vec{\xi}, \phi \barS\, \text{data} \big) \\[2ex]
&= \pi\,\big( \vec{Y} \barS \vec{W}, \vec{\gamma}, \vec{\xi}, \phi, \text{data} \big)~ \pi\,\big( \vec{W} \barS \vec{\gamma}, \vec{\xi}, \phi, \text{data} \big)~ \pi\,\big( \vec{\xi} \barS \vec{\gamma}, \phi, \text{data} \big)~ \pi\,\big( \vec{\gamma} \barS \phi, \text{data} \big)~ \pi\,\big( \phi \barS\, \text{data} \big) \\[2ex]
&= \pi\,\big( \vec{Y} \barS \vec{W} \big)~ \pi\,\big( \vec{W} \barS \vec{\gamma}, \vec{\xi}, \text{data} \big)~ \pi\,\big( \vec{\xi} \barS \phi \big)~ \pi\,\big( \vec{\gamma} \big)~ \pi\,\big( \phi \big) \\[1ex]
&= \Bigg( \prod_{i,j} \pi\,\big( Y_{ij} \barS \vec{W}_{ij} \big) \Bigg) \Bigg( \prod_{i,j,k{:}\, X_{ijk}=1} \hspace{-2mm} \pi\,\big( W_{ijk} \barS \vec{\gamma}, \vec{\xi} \big) \Bigg) \left( \prod_{i=1}^n \pi\,\big( \xi_i \barS \phi \big) \right)\left( \prod_{\ell=1}^q \pi\,\big(\gamma_h\big) \right)\, \pi\,\big( \phi \big) \\
&= \left\{ \prod_{i,j}\, \left[~ \ind\left( \sum_{k=1}^K W_{ijk} > 0 \right) Y_{ij} + \ind\left( \sum_{k=1}^K W_{ijk} = 0 \right) \big(1 - Y_{ij}\big)\,  \right] \right\} \\
& \hspace{20mm} \times~ \left( \prod_{i,j,k{:}\, X_{ijk}=1} \hspace{0mm} \frac{ 1 }{ W_{ijk}! }\, \left[ \xi_i \exp\left( \sum_{\ell=1}^q u_{ijk\ell} \log \gamma_\ell \right) \right]^{W_{ijk}} \exp\left\{ -\xi_i \exp\left( \sum_{\ell=1}^q u_{ijk\ell} \log \gamma_\ell \right) \right\}  \right) \\
& \hspace{20mm} \times~ \left( \prod_{i=1}^n \frac{ \phi^\phi }{ \Gamma(\phi) }\, \xi_i^{\phi-1} \exp\big( -\phi \xi_i \big) \right) \\
& \hspace{20mm} \times~ \left( \prod_{\ell=1}^q\, \bigg[ p_h \ind\big( \gamma_h = 1 \big) ~+~ (1 - p_h)\, \ind\big( \gamma_h \ne 1 \big)\, \mathcal{G}_{\mathcal{A}_h} (\gamma_h;\, a_h,b_h) \bigg] \right) \\[0.5ex]
& \hspace{20mm} \times~ \frac{ c_2^{c_1} }{ \Gamma(c_1) }\, \phi^{c_1-1} \exp\big( -c_2 \phi \big)
\end{align*}





%-------------------------------------------------------------------------------

\subsection{The full conditional distributions}

\begin{enumerate}[label=Step \arabic*., leftmargin=13mm, itemsep=10mm]
\item Writing $\vec{W}_{ij} = \big( W_{ij1},\dots,W_{ijK} \big)$ and letting $\vec{m} = \big(m_1,\dots,m_K\big)$ be a vector of realized outcomes for $\vec{W}_{ij}$, we see first that for $Y_{ij} = 0$ we have
\[ \prob\Big( \vec{W}_{ij} = \vec{m} \barM Y_{ij} = 0,\, \vec{\beta}, \phi, \vec{\xi}, \text{data} \Big) ~=~ \left\{ \begin{array}{lll} 1, & & \vec{m} = \vec{0} \\[1ex] 0, & & \text{else} \end{array} \right.  \]

Next, for $Y_{ij} = 1$ we have
\begin{align*} \MoveEqLeft
\prob\Big( \vec{W}_{ij} = \vec{m} \barM Y_{ij} = 1,\, \vec{\beta}, \phi, \vec{\xi}, \text{data} \Big) \\
&= \sum_{s=0}^\infty \prob\bigg( \vec{W}_{ij} = \vec{m},~ \textstyle \sum_{k} W_{ijk} = s \barB Y_{ij} = 1,\, \vec{\beta}, \phi, \vec{\xi}, \text{data} \bigg) \\[1ex]
&= \prob\bigg( \vec{W}_{ij} = \vec{m},~ \textstyle \sum_{k} W_{ijk} = \sum_k m_k  \barB Y_{ij} = 1,\, \vec{\beta}, \phi, \vec{\xi}, \text{data} \bigg) \\[1ex]
&= \prob\bigg( \vec{W}_{ij} = \vec{m} \barB \textstyle \sum_{k} W_{ijk} = \sum_k m_k,~  Y_{ij} = 1,\, \vec{\beta}, \phi, \vec{\xi}, \text{data} \bigg) \\
& \hspace{30mm} \times \prob\bigg( \textstyle \sum_{k} W_{ijk} = \sum_k m_k \barB  Y_{ij} = 1,\, \vec{\beta}, \phi, \vec{\xi}, \text{data} \bigg)
\end{align*}


%Now recalling that $\sum_{k=1}^{K} \text{Poisson}(\tau_k) \sim \text{Poisson} $
Furthermore,
\begin{align*} \MoveEqLeft
\pi\,\left( \sum_{k=1}^K W_{ijk} \barBBB Y_{ij} = 1,\, \vec{\beta}, \phi, \vec{\xi}, \text{data} \right) \\[1ex]
&=~ \pi\,\left( \sum_{k=1}^K W_{ijk} \barBBB \sum_{k=1}^K W_{ijk} \geq 1,\, \vec{\beta}, \phi, \vec{\xi}, \text{data} \right) \\
&\sim~ \text{Poisson} \left( \xi_i \sum_{k{:}~ X_{ijk}=1} \exp \left(\vec{u}_{ijk}^\prime \vec{\beta}\right) \right) \text{ truncated so that } \sum_{k=1}^K W_{ijk} \geq 1
\end{align*}
and
\begin{align*} \MoveEqLeft
\pi\,\left( \vec{W}_{ij} \barBBB \sum_{k=1}^K W_{ijk},~  Y_{ij} = 1,\, \vec{\beta}, \phi, \vec{\xi}, \text{data} \right) \\
&\sim~ \text{Multinomial}\, \left( \sum_{k=1}^K W_{ijk};~\, \frac{ X_{ij1} \xi_i \exp \left(\vec{u}_{ij1}^\prime \vec{\beta} \right) }{ \displaystyle \xi_i \sum_{k{:}~ X_{ijk}=1} \exp \left(\vec{u}_{ijk}^\prime \vec{\beta}\right) },~ \dots,~ \frac{ X_{ijK} \xi_i \exp\left( \vec{u}_{ijK}^\prime \vec{\beta} \right) }{ \displaystyle \xi_i \sum_{k{:}~ X_{ijk}=1} \exp \left(\vec{u}_{ijk}^\prime \vec{\beta}\right) } \right)
\end{align*}




%-------------------------------------------------------------------------------

\item Define the following terms which will be of use in the following derivation.  Denote
\[ \begin{array}{lll}
\widetilde{a}_h & & a_h + \sum_{i,j,k} u_{ijkh} W_{ijk} \\[2ex]
\widetilde{b}_h & & \displaystyle b_h +\hspace{2mm} \sum_{\mathclap{i,j,k{:}\, X_{ijk}=1}} \hspace{2mm} \xi_i \prod_{\ell \ne h} \gamma_\ell^{ u_{ijk\ell} } \\[4ex]
d_1 & \hspace{5mm} & p_h \exp\left\{ -(\widetilde{b}_h - b_h) \right\} \\[2ex]
d_2 &  & \displaystyle (1 - p_h)\, \frac{ C(a_h,b_h) \int_{\mathcal{A}_h} \mathcal{G}(\gamma;\, \widetilde{a}_h, \widetilde{b}_h)\, d\gamma }{ C(\widetilde{a}_h, \widetilde{b}_h) \int_{\mathcal{A}_h} \mathcal{G}(\gamma;\, a_h, b_h)\, d\gamma } \\[2ex]
\widetilde{p}_h & & \displaystyle \frac{ d_1 }{ d_1 + d_2 }
\end{array} \]


Then
\begin{align*} \MoveEqLeft
\pi\, \big( \gamma_h \barS \vec{\gamma}_{(-h)}, \phi, \vec{\xi}, \vec{W}, \text{data} \big) \\[2ex]
& \propto \pi\, \big( \vec{W} \barS\, \vec{\xi}, \gamma, \text{data} \big)\, \pi\,\big( \gamma_h \big) \\[1ex]
&= \left( \prod_{i=1}^{n} \prod_{j=1}^{n_i} \prod_{k{:}\, X_{ijk} = 1} \pi\, \big( W_{ijk} \barS \vec{\xi}_i, \gamma, \text{data} \big) \right) \pi\, \big( \gamma_h \big) \\
&\propto \left( \prod_{i=1}^{n} \prod_{j=1}^{n_i} \prod_{k{:}\, X_{ijk} = 1} \Big[ \exp\big( u_{ijkh} \log \gamma_h \big) \Big]^{W_{ijk}} \exp\left\{ -\xi_i \exp\left( \sum_{\ell=1}^q u_{ijk\ell} \log \gamma_{\ell} \right) \right\} \right) \pi\, \big( \gamma_h \big) \\
&= \left( \prod_{i=1}^{n} \prod_{j=1}^{n_i} \prod_{k{:}\, X_{ijk} = 1} \gamma_h^{ u_{ijkh} W_{ijk} } \exp\left\{ -\xi_i \prod_{\ell=1}^q \gamma_\ell^{ u_{ijk\ell} } \right\} \right) \pi\, \big( \gamma_h \big) \\
&= \gamma_h^{ \sum_{i,j,k} u_{ijkh} W_{ijk} } \exp\left\{ \gammaExpr \right\} \pi\, \big( \gamma_h \big) \\
&= \gamma_h^{ \sum_{i,j,k} u_{ijkh} W_{ijk} } \exp\left\{ \gammaExpr \right\} \\[1ex]
& \hspace{40mm} \times~ \bigg[ p_h \ind\big( \gamma_h = 1 \big) ~+~ (1 - p_h)\, \ind\big( \gamma_h \ne 1 \big)\, \mathcal{G}_{\mathcal{A}_h} (\gamma_h;\, a_h,b_h) \bigg] \\
&= p_h\, \ind\big( \gamma_h = 1 \big)\, \exp\left\{ \gammaExprNoH \right\} \\
& \hspace{10mm} +~ (1 - p_h)\, \ind\big(\gamma_h \ne 1 \big)\, \gamma_h^{ \sum_{i,j,k} u_{ijkh} W_{ijk} } \exp\left\{ \gammaExpr \right\} \, \mathcal{G}_{\mathcal{A}_h} (\gamma_h;\, a_h,b_h) \\
&= \color{QuestCol} p_h\, \ind\big( \gamma_h = 1 \big)\, \exp\left\{ \gammaExprNoH \right\} \\[1ex]
& \color{QuestCol} \hspace{30mm} +~ (1 - p_h)\, \ind\big(\gamma_h \ne 1 \big)\, \frac{ C(a_h,b_h) }{ \int_{\mathcal{A}_h} \mathcal{G}(\gamma;\, a_h,b_h)\, d\gamma }\, \gamma_h^{ a_h + \sum_{i,j,k} u_{ijkh} W_{ijk} - 1 } \\
& \color{QuestCol} \hspace{30mm} \times~ \exp\left\{ -\gamma_h \left[ b_h +\hspace{2mm} \sum_{\mathclap{i,j,k{:}\, X_{ijk}=1}} \hspace{2mm} \xi_i \prod_{\ell \ne h} \gamma_\ell^{ u_{ijk\ell} } \right] \right\} \\[2ex]
&= p_h\, \ind\big( \gamma_h = 1 \big)\, \exp\left\{ -(\widetilde{b}_h - b_h) \right\} \,+~ (1 - p_h)\, \ind\big( \gamma_h \ne 1 \big)\, \frac{ C(a_h,b_h) }{ \int_{\mathcal{A}_h} \mathcal{G}(\gamma;\, a_h,b_h)\, d\gamma }\, \gamma_h^{ \widetilde{a}_h - 1 }\, \exp\left\{ -\widetilde{b}_h \gamma_h \right\} \\[2ex]
&= p_h\, \ind\big( \gamma_h = 1 \big)\, \exp\left\{ -(\widetilde{b}_h - b_h) \right\} \,+~ (1 - p_h)\, \ind\big( \gamma_h \ne 1 \big) \\
& \hspace{30mm} \times~ \frac{ C(a_h,b_h) \int_{\mathcal{A}_h} \mathcal{G}(\gamma;\, \widetilde{a}_h, \widetilde{b}_h)\, d\gamma }{ C(\widetilde{a}_h, \widetilde{b}_h) \int_{\mathcal{A}_h} \mathcal{G}(\gamma;\, a_h, b_h)\, d\gamma }\, \frac{ C( \widetilde{a}_h, \widetilde{b}_h) }{ \int_{\mathcal{A}_h} \mathcal{G}(\gamma;\, \widetilde{a}_h, \widetilde{b}_h)\, d\gamma } \gamma_h^{ \widetilde{a}_h - 1 }\, \exp\left\{ -\widetilde{b}_h \gamma_h \right\} \\[2ex]
&= p_h\, \ind\big( \gamma_h = 1 \big)\, \exp\left\{ -(\widetilde{b}_h - b_h) \right\} \,+~ (1 - p_h)\, \ind\big( \gamma_h \ne 1 \big)\, \\
& \hspace{70mm} \times~ \frac{ C(a_h,b_h) \int_{\mathcal{A}_h} \mathcal{G}(\gamma;\, \widetilde{a}_h, \widetilde{b}_h)\, d\gamma }{ C(\widetilde{a}_h, \widetilde{b}_h) \int_{\mathcal{A}_h} \mathcal{G}(\gamma;\, a_h, b_h)\, d\gamma }\, \mathcal{G}_{\mathcal{A}_h} (\gamma;\, \widetilde{a}_h, \widetilde{b}_h) \\[2ex]
&= d_1 \ind\big( \gamma_h = 1 \big) ~+~ d_2 \ind\big( \gamma_h \ne 1 \big)\, \mathcal{G}_{\mathcal{A}_h} (\gamma;\, \widetilde{a}_h, \widetilde{b}_h) \\[2ex]
&\propto \frac{ d_1 }{ d_1 + d_2 } \ind\big( \gamma_h = 1 \big) ~+~ \frac{ d_2 }{ d_1 + d_2 } \ind\big( \gamma_h \ne 1 \big)\, \mathcal{G}_{\mathcal{A}_h} (\gamma;\, \widetilde{a}_h, \widetilde{b}_h) \\[2ex]
&= \widetilde{p}_h \ind\big( \gamma_h = 1 \big) ~+~ (1 - \widetilde{p}_h)\, \ind\big( \gamma_h \ne 1 \big)\, \mathcal{G}_{\mathcal{A}_h} (\gamma;\, \widetilde{a}_h, \widetilde{b}_h) \\
\end{align*}




%-------------------------------------------------------------------------------

\item 
\begin{align*} \MoveEqLeft
\pi\, \Big( \vec{\xi}_i \barM \vec{\beta}, \phi, \vec{W}, \text{data} \Big) \\[2ex]
&\propto \pi\,\Big( \vec{W}_i \barM \vec{\beta}, \xi_i, \text{data} \Big)~ \pi\, \big( \xi_i \barS \phi, \text{data} \big) \\[1ex]
&= \left( \prod_{j,k{:}\, X_{ijk}=1} \pi\,\Big( \vec{W}_{ijk} \barM \vec{\beta}, \xi_i, \text{data} \Big) \right) \pi\, \big( \xi_i \barS \phi, \text{data} \big) \\[1ex]
&\propto \left( \prod_{j,k{:}\, X_{ijk}=1} \xi_i^{W_{ijk}} \exp\bigg\{ -\xi_i \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) \bigg\} \right)\, \xi_i^{\phi - 1} \exp\big\{ -\phi \xi_i \big\} \\[1ex]
&= \left( \xi_i^{\sum_{j,k} W_{ijk}} \exp\Bigg\{ -\xi_i \hspace{2mm} \sum_{\mathclap{ j,k{:}\, X_{ijk}=1 }} \hspace{2mm} \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) \Bigg\} \right)\, \xi_i^{\phi - 1} \exp\big\{ -\phi \xi_i \big\} \\[1ex]
&= \xi_i^{ \phi + \sum_{j,k} W_{ijk} - 1 } \exp\left\{ -\xi_i\, \Bigg[ \phi + \hspace{2mm} \sum_{\mathclap{ j,k{:}\, X_{ijk}=1 }} \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) \Bigg] \right\} \\
& \sim \text{Gamma}\,\left(\phi + \hspace{1mm} \sum_{j,k} W_{ijk}, \hspace{4mm} \phi~ +  \sum_{j,k{:}\, X_{ijk}=1 }\hspace{-2mm} \exp\left( \vec{u}_{ijk}^\prime \vec{\beta} \right) \right)
\end{align*}





%-------------------------------------------------------------------------------

\item Sampling $\phi$ can be achieved via the Metropolis algorithms.  Let $\phi^{(s)}$ denote the value of $\phi$ for the $s^{\text{th}}$ scan of the MCMC algorithm, and let $\phi^*$ denote a proposed value of $\phi$ for the $(s+1)^{\text{th}}$ scan of the algorithm.  We consider the following two proposal distributions where $\delta$ is a tuning parameter with value greater than 0. \vspace{2mm}

\begin{enumerate}[label=(\roman*), itemsep=3mm]
\item $ J\left( \phi^* \barS \phi^{(s)} \right) \sim \left|\, N\left( \phi^{(s)}, \delta^2 \right) \,\right| $
\item $ J\left( \phi^* \barS \phi^{(s)} \right) \sim \left|\, \text{Uniform}\, \big( \phi^{(s)} - \delta,~ \phi^{(s)} + \delta \big) \,\right| $
\end{enumerate} \vspace{6mm}


Now,
\begin{align*} \MoveEqLeft
\pi\, \big( \phi \barS \vec{Y}, \vec{W}, \vec{\beta}, \vec{\xi}, \text{data} \big) \\[1ex]
&= \frac{ \pi\,\big( \vec{Y}, \vec{W}, \vec{\beta}, \vec{\xi}, \phi, \text{data} \big) }{ \pi\,\big( \vec{Y}, \vec{W}, \vec{\beta}, \vec{\xi}, \text{data} \big) } \\[1ex]
&= \frac{ 1 }{ \pi\,\big( \vec{Y}, \vec{W}, \vec{\beta}, \vec{\xi}, \text{data} \big) }\, \pi\,\big( \vec{Y} \barS \vec{W}, \vec{\beta}, \vec{\xi}, \phi, \text{data} \big)~ \pi\,\big( \vec{W} \barS \vec{\beta}, \vec{\xi}, \phi, \text{data} \big)\\
& \hspace{70mm} \times~ \pi\,\big( \vec{\xi} \barS \phi, \text{data} \big)~ \pi\,(\phi \barS \text{data}) \\[1ex]
&= \frac{ 1 }{ \pi\,\big( \vec{Y}, \vec{W}, \vec{\beta}, \vec{\xi}, \text{data} \big) }\, \pi\,\big( \vec{Y} \barS \vec{W} \big)~ \pi\,\big( \vec{W} \barS \vec{\beta}, \vec{\xi}, \text{data} \big)~ \pi\,\big( \vec{\xi} \barS \phi \big)~ \pi\,(\phi) \\[1ex]
&= \left( \prod_{i=1}^n \pi\,\big( \xi_i \barS \phi \big) \right) \pi\,(\phi)~ \frac{ \pi\,\big( \vec{Y} \barS \vec{W} \big)~ \pi\,\big( \vec{W} \barS \vec{\beta}, \vec{\xi}, \text{data} \big) }{ \pi\,\big( \vec{Y}, \vec{W}, \vec{\beta}, \vec{\xi}, \text{data} \big) }
\end{align*}


It follows that the acceptance ratio is given by $\min(r,1)$ where
\begin{align*}
r &= \frac{ \pi\, \big( \phi^* \barS \vec{Y}, \vec{W}, \vec{\beta}, \vec{\xi}, \text{data} \big) }{ \pi\, \big( \phi^{(s)} \barS \vec{Y}, \vec{W}, \vec{\beta}, \vec{\xi}, \text{data} \big) } = \frac{ \bigg( \prod_{i=1}^n \pi\,\big( \xi_i \barS \phi^* \big) \bigg)\, \pi\,(\phi^*) }{ \bigg( \prod_{i=1}^n \pi\,\big( \xi_i \barS \phi^{(s)} \big) \bigg)\, \pi\,(\phi^{(s)}) }
\end{align*}

\end{enumerate}




%-------------------------------------------------------------------------------

\subsubsection{Symmetric distributions verfication}

Recall the proposal distributions from Step 4 of the MCMC algorithm:
\begin{enumerate}[label=(\roman*), itemsep=3mm]
\item $ J\left( \phi^* \barS \phi^{(s)} \right) \sim \left|\, N\left( \phi^{(s)}, \delta^2 \right) \,\right| $
\item $ J\left( \phi^* \barS \phi^{(s)} \right) \sim \left|\, \text{Uniform}\, \big( \phi^{(s)} - \delta,~ \phi^{(s)} + \delta \big) \,\right| $
\end{enumerate}

\vspace{0mm} \begin{center} \rule{1.0\textwidth}{0.25mm} \end{center} \vspace{4mm}


\noindent To see that (i) is indeed a symmetric distribution, consider the following.  Let $X \sim \text{Normal}\, (\mu,\delta^2)$, and let $Y = |X|$.  Define
\[ \arraycolsep=5mm \begin{array}{lll}
A_0 = \{0\}       & & \\[1ex]
A_1 = (-\infty,0) & g_1(x) = -x & g_1^{-1}(x) = -x \\[1ex]
A_2 = (0, \infty) &  g_2(x) =x & g_2^{-1}(x) = x
\end{array} \]
Then
\begin{align*}
\pi_Y(y) &= \sum_{i=1}^2 f_X\left( g_i^{-1}(y) \right) \left| \frac{ d }{ d\,y } g_i^{-1}(y) \,\right| \\[1ex]
&= \frac{ 1 }{ \sqrt{ 2\pi\delta^2 } }\, \exp\left\{ - \frac{ 1 }{ \delta^2 }\, (-y - \mu)^2 \right\} | -1 \,| + \frac{ 1 }{ \sqrt{ 2\pi\delta^2 } }\, \exp\left\{ - \frac{ 1 }{ \delta^2 }\, (y - \mu)^2 \right\} |\, 1 \,|
\end{align*} \vspace{4mm}

\noindent Letting $\pi_{J\text{(i)}} \left( x | y \right)$ denote the density function of (i), it follows that 
\begin{align*}
\pi_{J\text{(i)}} \left( \phi^* \barS \phi^{(s)} \right) &= \frac{ 1 }{ \sqrt{ 2\pi\delta^2 } }\, \exp\left\{ - \frac{ 1 }{ \delta^2 } \left(-\phi^* - \phi^{(s)}\right)^2 \right\} + \frac{ 1 }{ \sqrt{ 2\pi\delta^2 } }\, \exp\left\{ - \frac{ 1 }{ \delta^2 } \left(\phi^* - \phi^{(s)}\right)^2 \right\}
\end{align*}
and that
\begin{align*}
\pi_{J\text{(i)}} \left( \phi^{(s)} \barS \phi^* \right) &= \frac{ 1 }{ \sqrt{ 2\pi\delta^2 } }\, \exp\left\{ - \frac{ 1 }{ \delta^2 } \left(-\phi^{(s)} - \phi^*\right)^2 \right\} + \frac{ 1 }{ \sqrt{ 2\pi\delta^2 } }\, \exp\left\{ - \frac{ 1 }{ \delta^2 } \left(\phi^{(s)} - \phi^*\right)^2 \right\}
\end{align*}
which are readily seen to be equivalent.

\vspace{4mm} \begin{center} \rule{1.0\textwidth}{0.25mm} \end{center} \vspace{4mm}
\noindent To see that (ii) is indeed a symmetric distribution, consider the following.  Let $X \sim \text{Uniform}\, (a,b)$, and let $Y = |X|$.  Then for $a < y < b$,
\begin{align*}
F_Y(y) &= \prob(Y \leq y) \\[1ex]
&= \prob(|X| \leq y) \\[1ex]
&= \prob(-y \leq X \leq y) \\[1ex]
&= F_X(y) - F_X(-y) \\[1ex]
&= \frac{ y-a }{ b-a } - \frac{ -y-a }{ b-a }\, \ind\,(a < -y)
\end{align*}
so that
\[ \pi_Y(y) = \frac{ 1 }{ b-a } + \frac{ 1 }{ b - a }\, \ind\,(a < -y)  \] \vspace{4mm}

\noindent Letting $\pi_{J\text{(ii)}} \left( x | y \right)$ denote the density function of (ii), it follows that for $\phi^{(s)} < \phi^* < \phi^{(s)}$,
\begin{align*}
\pi_{J\text{(ii)}} \left( \phi^* \barS \phi^{(s)} \right) &= \frac{ 1 }{ (\phi^{(s)} + \delta) - (\phi^{(s)} - \delta) } + \frac{ 1 }{ (\phi^{(s)} + \delta) - (\phi^{(s)} - \delta) }\, \ind\,(\phi^{(s)} - \delta < -\phi^*)  \\[1ex]
&= \frac{ 1 }{ 2\delta } + \frac{ 1 }{ 2\delta }\, \ind\big(\phi^{(s)} - \delta < -\phi^{*}\big)
\end{align*}
and similarly that for $\phi^{*} < \phi^{(s)} < \phi^{*}$,
\begin{align*} \pi_{J\text{(ii)}} \left( \phi^{(s)} \barS \phi^{*} \right) &= \frac{ 1 }{ (\phi^{*} + \delta) - (\phi^{*} - \delta) } + \frac{ 1 }{ (\phi^{*} + \delta) - (\phi^{*} - \delta) }\, \ind\,(\phi^{*} - \delta < -\phi^{(s)}\big) \\[1ex]
&= \frac{ 1 }{ 2\delta } + \frac{ 1 }{ 2\delta }\, \ind\big(\phi^{*} - \delta < -\phi^{(s)}\big)
\end{align*}
which after rearranging terms are seen to be equivalent.




%-------------------------------------------------------------------------------

\subsubsection{Computational considerations}

\begin{enumerate}[label=(\roman*), itemsep=10mm]
\item \textbf{Sampling from a truncated gamma distribution}

Consider a set $(a,b)$ and let $X$ be a continuous random variable with support $\mathcal{A}$ such that $(a,b) \subset \mathcal{A}$.  Define
\[ \begin{array}{lll}
F_X & & \text{the distribution function of $X$} \\[1ex]
U\,(d_1,d_2) & & \text{a uniform random variable with support on $(d_1,d_2)$} \\[1ex]
V & & \text{a random variable defined by $V = F_X^{-1}\Big( U\big( F_X(a), F_X(b) \big) \Big)$}
\end{array} \]
Then
\begin{align*} \MoveEqLeft
\prob(V \leq v) = \prob \bigg\{ F_X^{-1}\Big( U\big( F_X(a), F_X(b) \big) \Big) \leq v \bigg\} \\[1ex]
&= \prob \bigg\{ U\big( F_X(a), F_X(b) \big) \leq F_X(v) \bigg\} \\[1ex]
&= \left\{ \begin{array}{lll}
0, & & v \leq F_X(a) \\[1ex]
\displaystyle \frac{ F_X(v) - F_X(a) }{ F_X(b) - F_X(a) }, & & F_X(a) < v < F_X(b) \\[2ex]
1, & & F_X(b) \leq v
\end{array} \right. \end{align*}
which is the distribution function of $X$ truncated to $(a,b)$.  Thus by choosing $F_X$ to be the distribution function of some desired gamma distribution, we may sample from the truncated gamma distribution by sampling $u = U\big( F_X(a), F_X(b) \big)$ and then calculating $F_X^{-1}(u)$. 


\item \textbf{Sampling from a truncated Poisson distribution}

Let $X$ be a random variable with support $\{x_1, x_2, \dots\}$ where $x_i < x_j$ for all $i < j$.  Let $F_X$ denote the distribution function of $X$, and let $G_X{:}~ [0,1) \mapsto \{x_1,x_2,\dots\}$ be a pseudo-inverse of $F_X$ defined by
\[ G_X(p) = \min\Big\{ x_{i}{:}~ F_X(x_i) < p \Big\} \]
Next, let $j_1, j_2, k \in \mathbb{N}$ with $j_1 < j_2$ (note that this implies that $x_{j_1} < x_{j_2}$).  Define $U(d_1,d_2)$ to be a uniform random variable with support on $(d_1,d_2)$, then
\begin{align*} \MoveEqLeft
\prob \bigg\{ G_X\Big( U\left( F_X(x_{j_1-1}), F_X(x_{j_2}) \right) \Big) = x_k \bigg\} \\[1ex]
&= \prob \bigg\{ U\left( F_X(x_{j_1-1}), F_X(x_{j_2}) \right) \in \Big( F_X(x_{k-1}),\, F_X(x_k) \Big) \bigg\} \\[1ex]
&= \ind\left(x_{j_1} \leq x_{k},\, x_{k} \leq x_{j_2}\right) \int_{F_X(x_{k-1})}^{F_X(x_k)} \frac{ 1 }{ F_X(x_{j_2}) - F_X(x_{j_1-1}) }\, dy \\[1ex]
&= \ind\left(x_{j_1} \leq x_{k},\, x_{k} \leq x_{j_2}\right)\, \frac{ F_X(x_k) - F_X(x_{k-1}) }{ F_X(x_{j_2}) - F_X(x_{j_1-1}) } \\[1ex]
&= \ind\left(x_{j_1} \leq x_{k},\, x_{k} \leq x_{j_2}\right)\, \frac{ \prob(X = k) }{ F_X(x_{j_2}) - F_X(x_{j_1-1}) }
\end{align*}
which is the probability mass function of $X$ truncated to $\{x_{j_1},\dots, x_{j_2}\}$.  Notice that we may replace $F_X(x_{j_2})$ with 1 throughout to obtain the pmf of $X$ truncated to $\{x_{j_1}, x_{j_1 + 1}, x_{x_1 + 2},\dots\}$.  Thus by choosing $F_X$ to be the distribution of a Poisson distribution with mean $\lambda$, we may sample from the Poisson distribution truncated to be greater than or equal to 1 by sampling $u = U\big( F_X(0),\, 1\big) = U\big( e^{-\lambda}, 1 \big)$ and then calculating $G_X(u)$.





\item \textbf{Calculating } $\displaystyle \boldsymbol{\frac{d_1}{d_1 + d_2}}$

\item \textbf{Sampling from acceptance ratio $\boldsymbol{r}$}

\end{enumerate}






%===============================================================================

\section{Posterior inference}


\end{document}







